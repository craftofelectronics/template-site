<p>Suppose I were about to measure an unknown voltage with a manual-range voltmeter. This particular voltmeter has several different voltage measurement ranges to choose from:</p>
<p><span class="math"> • </span> 500 volts</p>
<p><span class="math"> • </span> 250 volts</p>
<p><span class="math"> • </span> 100 volts</p>
<p><span class="math"> • </span> 50 volts</p>
<p><span class="math"> • </span> 25 volts</p>
<p><span class="math"> • </span> 10 volts</p>
<p><span class="math"> • </span> 5 volts</p>
<p>What range would be best to begin with, when first measuring this unknown voltage with the meter? Explain your answer.</p>
<p>Begin by setting the voltmeter to its highest range: 500 volts. Then, see if the movement needle registers anything with the meter leads connected to the circuit. Decide to change the meter’s range based on this first indication.</p>
<p>I always like to have my students begin their test equipment familiarity by using old-fashioned analog multimeters. Only after they have learned to be proficient with an inexpensive meter do I allow them to use anything better (digital, auto-ranging) in their work. This forces students to appreciate what a &quot;fancy&quot; meter does for them, as well as teach them basic principles of instrument ranging and measurement precision.</p>
